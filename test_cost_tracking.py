#!/usr/bin/env python3
"""
Test script to verify that Langfuse cost tracking is properly implemented
"""

import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Test imports
try:
    from langfuse import Langfuse
    print("‚úÖ Langfuse import successful")
except Exception as e:
    print(f"‚ùå Langfuse import failed: {e}")
    exit(1)

try:
    from openai import OpenAI
    print("‚úÖ OpenAI import successful")
except Exception as e:
    print(f"‚ùå OpenAI import failed: {e}")
    exit(1)

# Initialize clients
try:
    langfuse = Langfuse(
        public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
        secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
        host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
    )
    print("‚úÖ Langfuse client initialized")
except Exception as e:
    print(f"‚ùå Langfuse client initialization failed: {e}")
    exit(1)

try:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    print("‚úÖ OpenAI client initialized")
except Exception as e:
    print(f"‚ùå OpenAI client initialization failed: {e}")
    exit(1)

# Test a simple generation with cost tracking
def test_cost_tracking():
    print("\nüß™ Testing cost tracking with a simple generation...")
    
    # Test messages
    messages = [
        {"role": "system", "content": "You are a helpful assistant. Respond with exactly one word."},
        {"role": "user", "content": "Say hello"}
    ]
    
    # Create a generation for proper cost tracking
    generation = langfuse.start_generation(
        name="test_generation",
        model="gpt-4o",
        input=messages,
        metadata={"temperature": 0.1, "max_tokens": 5}
    )
    
    try:
        # Make API call
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.1,
            max_tokens=5
        )
        
        output = response.choices[0].message.content.strip()
        
        # Update generation with output and usage data for cost tracking
        generation.update(
            output=output,
            usage_details={
                "input": response.usage.prompt_tokens,
                "output": response.usage.completion_tokens,
                "total": response.usage.total_tokens
            }
        )
        
        # End the generation
        generation.end()
        
        print(f"‚úÖ Cost tracking test successful!")
        print(f"   Response: {output}")
        print(f"   Tokens used: {response.usage.total_tokens}")
        print(f"   Input tokens: {response.usage.prompt_tokens}")
        print(f"   Output tokens: {response.usage.completion_tokens}")
        print("\nüéâ Generation with usage tracking has been sent to Langfuse!")
        print("   Check your Langfuse dashboard - you should now see model costs!")
        
    except Exception as e:
        generation.end()
        print(f"‚ùå Cost tracking test failed: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("üîç Testing Langfuse cost tracking implementation...")
    success = test_cost_tracking()
    
    if success:
        print("\n‚úÖ All tests passed! Cost tracking should now be working in Langfuse.")
        print("üí° The key changes made:")
        print("   - Replaced spans with generations for OpenAI API calls")
        print("   - Added usage data (input/output/total tokens) to generations")
        print("   - Updated all agent files with proper cost tracking")
    else:
        print("\n‚ùå Tests failed. Please check the error messages above.")
